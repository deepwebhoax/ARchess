{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "figures_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYJix2R0es6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5ec4a5-0473-4dd1-92ef-49b464de1444"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import copy\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from albumentations import pytorch as AT\n",
        "import albumentations as A\n",
        "import torchvision.datasets as dataset\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import natsort\n",
        "!pip install -U skorch\n",
        "%matplotlib inline\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCZtiU84eERG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf949e43-870d-4b1b-c781-eedebdf2b2fe"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 21 13:22:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R05_voFGxBV6"
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.dataset import CVSplit\n",
        "from skorch.callbacks import LRScheduler, Checkpoint \n",
        "from skorch.callbacks import Freezer, EarlyStopping\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# for multiprocessing\n",
        "import multiprocessing as mp\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "416X_VTZ2HVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685c89b6-a49b-42aa-8940-ba130e4da88a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4cuXj-GJGoz"
      },
      "source": [
        "train_dir='/content/drive/MyDrive/dataset/dataset'\n",
        "image_label='/content/drive/MyDrive/last_labels.csv'\n",
        "train_files=os.listdir(train_dir)\n",
        "labels=pd.read_csv(image_label)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQCcJb0f56Qe",
        "outputId": "0690650a-725a-4b98-840b-59c8c34dd880"
      },
      "source": [
        "len(train_files)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dttS6MZRoCD",
        "outputId": "dfe52467-4746-44bf-f4b6-7457d2339e54"
      },
      "source": [
        "labels['class'].value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9     145\n",
              "10    136\n",
              "3     132\n",
              "12    126\n",
              "8     126\n",
              "6     120\n",
              "4     120\n",
              "2     120\n",
              "0     120\n",
              "11    112\n",
              "7     108\n",
              "5      96\n",
              "1      91\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "TervByu108eh",
        "outputId": "f40625a3-5acd-4f0c-a415-e0043b91684c"
      },
      "source": [
        "labels"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500_2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>501</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>79_0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1548</th>\n",
              "      <td>79_1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>79_2</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1550</th>\n",
              "      <td>79_3</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>79_4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1552 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image  class\n",
              "0       500      0\n",
              "1     500_0      0\n",
              "2     500_1      0\n",
              "3     500_2      0\n",
              "4       501      0\n",
              "...     ...    ...\n",
              "1547   79_0     12\n",
              "1548   79_1     12\n",
              "1549   79_2     12\n",
              "1550   79_3     12\n",
              "1551   79_4     12\n",
              "\n",
              "[1552 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDAZp4NelJW4"
      },
      "source": [
        "import multiprocessing\n",
        "class DatasetRetriever(Dataset):\n",
        "  def __init__(self, dir,image_list,labels, transform=None,mode='train'):\n",
        "        self.dir = dir\n",
        "        self.labels = labels\n",
        "        self.image_list=image_list\n",
        "        self.label=0\n",
        "        self.mode=mode\n",
        "        self.image_name=None\n",
        "        self.full_path=None\n",
        "        self.transform=transform\n",
        "        self.image=None\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "  def __getitem__(self, idx: int):       \n",
        "        self.image_name = self.image_list[idx]\n",
        "        self.full_path = os.path.join(self.dir, self.image_name)\n",
        "        if self.mode=='train':\n",
        "            #if self.image_name.split('.')[0] in self.labels['image'].unique():\n",
        "                self.image = cv2.imread(self.full_path)\n",
        "                self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
        "                self.label= int(self.labels[self.labels['image']==self.image_name.split('.')[0]]['class'].values[0])\n",
        "        else:\n",
        "            self.image = cv2.imread(self.full_path)\n",
        "            self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=self.image)\n",
        "            self.image = augmented['image']\n",
        "        if self.mode == 'train':\n",
        "            return self.image, self.label\n",
        "        else:\n",
        "            return self.image, self.image_name.split('.')[0]\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRvHaSRH5ptS"
      },
      "source": [
        "batch_size = 1\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "img_size=96"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZUzmz3U557F"
      },
      "source": [
        "data_transforms = A.Compose([\n",
        "    A.Resize(96, 96),                         \n",
        "    A.augmentations.transforms.HorizontalFlip(p=0.5),\n",
        "    A.augmentations.transforms.Transpose(p=0.5),\n",
        "    A.augmentations.transforms.ShiftScaleRotate(p=0.5),\n",
        "    A.augmentations.transforms.VerticalFlip(p=0.5),\n",
        "    A.augmentations.transforms.HueSaturationValue(hue_shift_limit=0.1, sat_shift_limit=0.1, val_shift_limit=0.1, p=0.5),\n",
        "    A.augmentations.transforms.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "    #A.Crop(x_min=int(3*img_size/10),x_max=int(7*img_size/10),y_min=int(*img_size/10),y_max=int(6*img_size/10)),\n",
        "    #A.Normalize((2.7176417e-05, -0.00011741407, -0.0004583559), (0.0038161594, 0.003801249, 0.0035198121))\n",
        "    A.Normalize(),\n",
        "    AT.ToTensor()\n",
        "    ])\n",
        "\n",
        "data_transforms_test = A.Compose([\n",
        "    A.Resize(96, 96),\n",
        "     A.Normalize(),\n",
        "    AT.ToTensor()\n",
        "    ])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhKKaoJMIYUX"
      },
      "source": [
        "trainset = DatasetRetriever(train_dir, train_files,labels, transform = data_transforms)\n",
        "#testset = DatasetRetriever(test_dir, test_files,image_label,transform=data_transforms_test, mode = \"test\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9_o7uw9qp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539e20ac-796d-4e05-d33e-0d99a163d9e6"
      },
      "source": [
        "len(trainset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9t4QnpNe3W3"
      },
      "source": [
        "valid_size = int(len(train_files) * 0.2)\n",
        "trainset, validset = random_split(trainset, \n",
        "                                  (len(train_files)-valid_size, valid_size))\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_KbfUUuL9ZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "13fb26bb-2741-40f9-c2d5-3232a3648148"
      },
      "source": [
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, pin_memory=True, \n",
        "                                        batch_size=batch_size)\n",
        "validloader = DataLoader(validset, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "'''\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\n",
        "                                         num_workers = num_workers)'''"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\\n                                         num_workers = num_workers)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTRvOtXfItA5"
      },
      "source": [
        "samples,files = next(iter(validloader))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpyFyNfiIx9z",
        "outputId": "972e36d7-da63-4d03-f145-e054d92c1145"
      },
      "source": [
        "files"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12,  7,  8,  4, 11,  1, 11,  1,  8, 10,  3,  9, 10,  2,  3,  3,  4, 10,\n",
              "         0,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsKHhr2F8Yr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f2782d20-2e7a-43a9-8fe7-29c4bf8f9e78"
      },
      "source": [
        "'''mean0=[]\n",
        "mean1=[]\n",
        "mean2=[]\n",
        "std1=[]\n",
        "std2=[]\n",
        "std3=[]\n",
        "\n",
        "for i in range(449):\n",
        "  mean0.append(samples[i,0,:,:].mean())\n",
        "  mean1.append(samples[i,1,:,:].mean())\n",
        "  mean2.append(samples[i,2,:,:].mean())\n",
        "  std1.append(samples[i,0,:,:].std())\n",
        "  std2.append(samples[i,1,:,:].std())\n",
        "  std3.append(samples[i,2,:,:].std())\n",
        "\n",
        "print((np.mean(mean0),np.mean(mean1),np.mean(mean2)),(np.mean(std1),np.mean(std2),np.mean(std3)))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mean0=[]\\nmean1=[]\\nmean2=[]\\nstd1=[]\\nstd2=[]\\nstd3=[]\\n\\nfor i in range(449):\\n  mean0.append(samples[i,0,:,:].mean())\\n  mean1.append(samples[i,1,:,:].mean())\\n  mean2.append(samples[i,2,:,:].mean())\\n  std1.append(samples[i,0,:,:].std())\\n  std2.append(samples[i,1,:,:].std())\\n  std3.append(samples[i,2,:,:].std())\\n\\nprint((np.mean(mean0),np.mean(mean1),np.mean(mean2)),(np.mean(std1),np.mean(std2),np.mean(std3)))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOSCf1TqF2dg"
      },
      "source": [
        "model = torchvision.models.mobilenet_v2(pretrained=True,progress=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GqyJNBCGDmx"
      },
      "source": [
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1]=nn.Linear(in_features, 13)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKORDIk8F2at",
        "outputId": "4d984ef7-38fd-4045-b846-423a5e6734d8"
      },
      "source": [
        "model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=13, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m32e1SF9F2YF"
      },
      "source": [
        "def train_model(model_conv, train_loader, valid_loader, criterion, optimizer, sheduler, n_epochs):\n",
        "    model_conv.to(device)\n",
        "    valid_loss_min = np.Inf\n",
        "    patience = 20\n",
        "    # сколько эпох ждем до отключения\n",
        "    p = 0\n",
        "    # иначе останавливаем обучение\n",
        "    stop = False\n",
        "\n",
        "    # количество эпох\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "          print(time.ctime(), 'Epoch:', epoch)\n",
        "          b_i=0\n",
        "          train_loss = []\n",
        "\n",
        "          for batch_i, (data, target) in enumerate(train_loader):\n",
        "              b_i+=1\n",
        "              data, target = data.to(device), target.to(device)\n",
        "              optimizer.zero_grad()\n",
        "              output = model_conv(data)\n",
        "              loss = criterion(output, target)\n",
        "              train_loss.append(loss.item())\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              if b_i % 10 == 0: \n",
        "                  print(b_i)\n",
        "      # запускаем валидацию\n",
        "          model_conv.eval()\n",
        "          val_loss = []\n",
        "          for batch_i, (data, target) in enumerate(valid_loader):\n",
        "              data, target = data.to(device), target.to(device)\n",
        "              output = model_conv(data)\n",
        "              loss = criterion(output, target)\n",
        "              val_loss.append(loss.item()) \n",
        "\n",
        "          print(f\"Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, lr: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "          valid_loss = np.mean(val_loss)\n",
        "          sheduler.step(valid_loss)\n",
        "          if valid_loss <= valid_loss_min:\n",
        "              print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "              valid_loss_min,\n",
        "              valid_loss))\n",
        "              torch.save(model_conv.state_dict(), '/content/drive/MyDrive/chess_weights/model_1.pt')\n",
        "              \n",
        "              valid_loss_min = valid_loss\n",
        "              p = 0\n",
        "\n",
        "          # проверяем как дела на валидации\n",
        "          if valid_loss > valid_loss_min:\n",
        "              p += 1\n",
        "              \n",
        "              print(f'{p} epochs of increasing val loss')\n",
        "              if p > patience:\n",
        "                  print('Stopping training')\n",
        "                  stop = True\n",
        "                  break        \n",
        "\n",
        "          if stop:\n",
        "              break\n",
        "\n",
        "        \n",
        "    return model_conv, train_loss, val_loss"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhDG1Z2vHZ3H",
        "outputId": "391963f6-c566-4d25-a96c-1a5b26b46627"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nWKxxEkF2VO"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)#,momentum=0.9,nesterov=True,lr=0.1)\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=0.00025,momentum=0.9,nesterov=True)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.2)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFa-i7YF2Se",
        "outputId": "d5f7fa3b-0f49-4e1d-8daf-2fa052be2130"
      },
      "source": [
        "model_mob, train_loss, val_loss = train_model(model, trainloader, validloader, criterion, \n",
        "                              optimizer, scheduler, n_epochs=400)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 21 10:31:58 2021 Epoch: 1\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 1, train loss: 1.1346, valid loss: 0.7476, lr: 0.001\n",
            "Validation loss decreased (inf --> 0.747617).  Saving model ...\n",
            "Sun Mar 21 10:41:31 2021 Epoch: 2\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 2, train loss: 2.6539, valid loss: 2.6109, lr: 0.001\n",
            "1 epochs of increasing val loss\n",
            "Sun Mar 21 10:41:38 2021 Epoch: 3\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 3, train loss: 2.5740, valid loss: 2.5926, lr: 0.001\n",
            "2 epochs of increasing val loss\n",
            "Sun Mar 21 10:41:44 2021 Epoch: 4\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 4, train loss: 2.5682, valid loss: 2.5870, lr: 0.001\n",
            "3 epochs of increasing val loss\n",
            "Sun Mar 21 10:41:51 2021 Epoch: 5\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 5, train loss: 2.5656, valid loss: 2.5858, lr: 0.001\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n",
            "4 epochs of increasing val loss\n",
            "Sun Mar 21 10:41:58 2021 Epoch: 6\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 6, train loss: 2.5596, valid loss: 2.5806, lr: 0.0005\n",
            "5 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:04 2021 Epoch: 7\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 7, train loss: 2.5585, valid loss: 2.5798, lr: 0.0005\n",
            "6 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:11 2021 Epoch: 8\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 8, train loss: 2.5582, valid loss: 2.5796, lr: 0.0005\n",
            "7 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:18 2021 Epoch: 9\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 9, train loss: 2.5581, valid loss: 2.5795, lr: 0.0005\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n",
            "8 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:25 2021 Epoch: 10\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 10, train loss: 2.5556, valid loss: 2.5785, lr: 0.00025\n",
            "9 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:31 2021 Epoch: 11\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 11, train loss: 2.5554, valid loss: 2.5779, lr: 0.00025\n",
            "10 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:38 2021 Epoch: 12\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 12, train loss: 2.5554, valid loss: 2.5777, lr: 0.00025\n",
            "11 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:45 2021 Epoch: 13\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 13, train loss: 2.5553, valid loss: 2.5776, lr: 0.00025\n",
            "Epoch    13: reducing learning rate of group 0 to 1.2500e-04.\n",
            "12 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:52 2021 Epoch: 14\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 14, train loss: 2.5541, valid loss: 2.5773, lr: 0.000125\n",
            "13 epochs of increasing val loss\n",
            "Sun Mar 21 10:42:58 2021 Epoch: 15\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 15, train loss: 2.5541, valid loss: 2.5771, lr: 0.000125\n",
            "14 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:05 2021 Epoch: 16\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 16, train loss: 2.5541, valid loss: 2.5770, lr: 0.000125\n",
            "15 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:12 2021 Epoch: 17\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 17, train loss: 2.5541, valid loss: 2.5769, lr: 0.000125\n",
            "Epoch    17: reducing learning rate of group 0 to 6.2500e-05.\n",
            "16 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:19 2021 Epoch: 18\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 18, train loss: 2.5535, valid loss: 2.5768, lr: 6.25e-05\n",
            "17 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:25 2021 Epoch: 19\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 19, train loss: 2.5535, valid loss: 2.5767, lr: 6.25e-05\n",
            "18 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:32 2021 Epoch: 20\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 20, train loss: 2.5535, valid loss: 2.5766, lr: 6.25e-05\n",
            "19 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:39 2021 Epoch: 21\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 21, train loss: 2.5535, valid loss: 2.5766, lr: 6.25e-05\n",
            "Epoch    21: reducing learning rate of group 0 to 3.1250e-05.\n",
            "20 epochs of increasing val loss\n",
            "Sun Mar 21 10:43:45 2021 Epoch: 22\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "Epoch 22, train loss: 2.5532, valid loss: 2.5765, lr: 3.125e-05\n",
            "21 epochs of increasing val loss\n",
            "Stopping training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MimyVbRYhBOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834096fa-4f75-47b0-f2a5-b13493a3150b"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS0gF4zfvHOU"
      },
      "source": [
        "\n",
        "# class which uses DenseNet169 pretrained model\n",
        "# + added custom classifier in the last layer\n",
        "class DenseNet169(nn.Module):\n",
        "    def __init__(self, output_features, num_units=512, drop=0.3,\n",
        "                 num_units1=256, drop1=0.1):\n",
        "        super().__init__()\n",
        "        model = torchvision.models.densenet169(pretrained=False)\n",
        "        n_inputs = model.classifier.in_features\n",
        "        model.classifier = nn.Sequential( nn.Linear(n_inputs, output_features))\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# class which uses VGG16 pretrained model\n",
        "class GoogleNet(nn.Module):\n",
        "    def __init__(self, output_features, num_units=512, drop=0.4,\n",
        "                 num_units1=256, drop1=0.1):\n",
        "        super().__init__()\n",
        "        model = torchvision.models.googlenet(pretrained=False,aux_logits=False)\n",
        "        \n",
        "        n_inputs = model.fc.in_features\n",
        "        model.fc = nn.Sequential( nn.Linear(n_inputs, output_features))\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self, output_features, num_units=512, drop=0.5,\n",
        "                 num_units1=256, drop1=0.2):\n",
        "        super().__init__()\n",
        "        model =  torchvision.models.mobilenet_v2(pretrained=False)\n",
        "        n_inputs = model.classifier[1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "                                nn.Dropout(p=drop1), \n",
        "                                nn.Linear(n_inputs, output_features))\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzX9ujv7Ea8O"
      },
      "source": [
        "lr_scheduler_densenet = LRScheduler(policy='StepLR',\n",
        "                                  step_size=8,gamma=0.15)\n",
        "# callback for saving the best on validation accuracy model\n",
        "checkpoint_densenet = Checkpoint(f_params='/content/drive/My Drive/Wheat_Growth_Stage/models/best_model4_densenet169.pkl',\n",
        "                                 monitor='valid_acc_best')\n",
        "# callback for freezing all layer of the model except the last layer\n",
        "#freezer_densenet = Freezer(lambda x: not x.startswith('model.classifier'))\n",
        "# callback for early stopping\n",
        "early_stopping_densenet = EarlyStopping(patience=10)\n",
        "\n",
        "# VGG16\n",
        "# callback for Reduce on Plateau scheduler \n",
        "lr_scheduler_googlenet = LRScheduler(policy='StepLR',\n",
        "                                  step_size=8,gamma=0.15)\n",
        "# callback for saving the best on validation accuracy model\n",
        "checkpoint_googlenet = Checkpoint(f_params='/content/drive/MyDrive/chess_weights/best_model4_googlenet.pkl',\n",
        "                            monitor='valid_acc_best')\n",
        "# callback for freezing all layer of the model except the last layer\n",
        "#freezer_vgg = Freezer(lambda x: not x.startswith('model.classifier'))\n",
        "# callback for early stopping\n",
        "early_stopping_googlenet = EarlyStopping(patience=10)\n",
        "\n",
        "lr_scheduler_mobilenet = LRScheduler(policy='StepLR',\n",
        "                                  step_size=8,gamma=0.2)\n",
        "# callback for saving the best on validation accuracy model\n",
        "checkpoint_mobilenet = Checkpoint(f_params='/content/drive/MyDrive/chess_weights/best_model_mobilenet.pkl',\n",
        "                            monitor='valid_acc_best')\n",
        "# callback for freezing all layer of the model except the last layer\n",
        "#freezer_vgg = Freezer(lambda x: not x.startswith('model.classifier'))\n",
        "# callback for early stopping\n",
        "early_stopping_mobilenet = EarlyStopping(patience=10)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEttbFrwKi2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e54b19a-dcc7-4ea0-f020-577e8251347c"
      },
      "source": [
        "mobilenet = NeuralNetClassifier(\n",
        "    # pretrained ResNet50 + custom classifier \n",
        "    module=MobileNet,          \n",
        "    # fine tuning model's inner parameters\n",
        "    module__output_features=13,\n",
        "    module__num_units=512,\n",
        "    module__drop=0.5,\n",
        "    module__num_units1=512,\n",
        "    module__drop1=0.5,\n",
        "    # criterion\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    # batch_size = 128\n",
        "    batch_size=batch_size,\n",
        "    # number of epochs to train\n",
        "    max_epochs=100,\n",
        "    # optimizer Adam used\n",
        "    optimizer=torch.optim.Adam,\n",
        "    optimizer__lr = 0.0025,\n",
        "    optimizer__weight_decay=1e-6,\n",
        "    # shuffle dataset while loading\n",
        "    iterator_train__shuffle=True,\n",
        "    # load in parallel\n",
        "    iterator_train__num_workers=num_workers,\n",
        "    # stratified kfold split of loaded dataset\n",
        "    train_split=CVSplit(cv=5, stratified=True, random_state=42),\n",
        "    # callbacks declared earlier\n",
        "    callbacks=[lr_scheduler_mobilenet, checkpoint_mobilenet, \n",
        "                early_stopping_mobilenet],\n",
        "    # use GPU or CPU\n",
        "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skorch/dataset.py:271: FutureWarning: Setting a random_state has no effect since cv is not a float. This will raise an error in a future. You should leave random_state to its default (None), or set cv to a float value.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhFPkxmNE9he"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq1qX_T1420W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83204b1-8feb-413d-8971-a4df16540da1"
      },
      "source": [
        "# NeuralNetClassifier for based on VGG16 with custom parameters\n",
        "googlenet = NeuralNetClassifier(\n",
        "    # pretrained VGG16\n",
        "    module=GoogleNet,\n",
        "    # fine tuning model's inner parameters\n",
        "    module__output_features=7, \n",
        "    # criterion\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    # batch_size = 128\n",
        "    batch_size=batch_size,\n",
        "    # number of epochs to train\n",
        "    max_epochs=100,\n",
        "    # optimizer Adam used\n",
        "    optimizer=torch.optim.Adam,\n",
        "    optimizer__lr = 0.01,\n",
        "    optimizer__weight_decay=1e-6,\n",
        "    # shuffle dataset while loading\n",
        "    iterator_train__shuffle=True,\n",
        "    # load in parallel\n",
        "    iterator_train__num_workers=num_workers, \n",
        "    # stratified kfold split of loaded dataset\n",
        "    train_split=CVSplit(cv=10, stratified=True, random_state=42),\n",
        "    # callbacks declared earlier\n",
        "    callbacks=[lr_scheduler_googlenet, checkpoint_googlenet,\n",
        "              early_stopping_googlenet],\n",
        "    # use GPU or CPU\n",
        "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skorch/dataset.py:271: FutureWarning: Setting a random_state has no effect since cv is not a float. This will raise an error in a future. You should leave random_state to its default (None), or set cv to a float value.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Ezi4m28F23"
      },
      "source": [
        "y_train = np.array([y for X, y in iter(trainset)])\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXodBjc79edF"
      },
      "source": [
        "mobilenet.fit(trainset, y=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd7WqiuDqVcN"
      },
      "source": [
        "mobilenet.initialize()\n",
        "\n",
        "#mobilenet.initialize()\n",
        "mobilenet.load_params(f_params='/content/drive/MyDrive/chess_weights/best_model4_mobilenet.pkl')\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf6Zjfayac29"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}