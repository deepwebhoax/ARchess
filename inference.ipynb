{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QrErE50YBf5",
        "outputId": "215022e5-9cda-4c11-c9c1-a51a1a8a1eb8"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import copy\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from albumentations import pytorch as AT\n",
        "import albumentations as A\n",
        "import torchvision.datasets as dataset\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import natsort\n",
        "!pip install -U skorch\n",
        "import time\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.dataset import CVSplit\n",
        "from skorch.callbacks import LRScheduler, Checkpoint \n",
        "from skorch.callbacks import Freezer, EarlyStopping\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# for multiprocessing\n",
        "import multiprocessing as mp\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WsZx1zaYCR-"
      },
      "source": [
        "class DatasetRetriever(Dataset):\n",
        "  def __init__(self, dir,image_list,labels, transform=None,mode='train'):\n",
        "        self.dir = dir\n",
        "        self.labels = labels\n",
        "        self.image_list=image_list\n",
        "        self.label=0\n",
        "        self.mode=mode\n",
        "        self.image_name=None\n",
        "        self.full_path=None\n",
        "        self.transform=transform\n",
        "        self.image=None\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "  def __getitem__(self, idx: int):       \n",
        "        self.image_name = self.image_list[idx]\n",
        "        self.full_path = os.path.join(self.dir, self.image_name)\n",
        "        if self.mode=='train':\n",
        "            #if self.image_name.split('.')[0] in self.labels['image'].unique():\n",
        "                self.image = cv2.imread(self.full_path)\n",
        "                self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
        "                self.label= int(self.labels[self.labels['image']==self.image_name.split('.')[0]]['class'].values[0])\n",
        "        else:\n",
        "            self.image = cv2.imread(self.full_path)\n",
        "            self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=self.image)\n",
        "            self.image = augmented['image']\n",
        "        if self.mode == 'train':\n",
        "            return self.image, self.label\n",
        "        else:\n",
        "            return self.image, self.image_name.split('.')[0]\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qct1YW10YGmR",
        "outputId": "04c70d31-bfc0-47fe-d216-36d61c2cbc60"
      },
      "source": [
        "class MobileNet(nn.Module):\n",
        "    def __init__(self, output_features, num_units=512, drop=0.5,\n",
        "                 num_units1=256, drop1=0.2):\n",
        "        super().__init__()\n",
        "        model =  torchvision.models.mobilenet_v2(pretrained=False)\n",
        "        n_inputs = model.classifier[1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "                                nn.Dropout(p=drop1), \n",
        "                                nn.Linear(n_inputs, output_features))\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "lr_scheduler_mobilenet = LRScheduler(policy='StepLR',\n",
        "                                  step_size=8,gamma=0.2)\n",
        "# callback for saving the best on validation accuracy model\n",
        "checkpoint_mobilenet = Checkpoint(f_params='/content/drive/MyDrive/chess_weights/best_model_mobilenet.pkl',\n",
        "                            monitor='valid_acc_best')\n",
        "# callback for freezing all layer of the model except the last layer\n",
        "#freezer_vgg = Freezer(lambda x: not x.startswith('model.classifier'))\n",
        "# callback for early stopping\n",
        "early_stopping_mobilenet = EarlyStopping(patience=10)\n",
        "mobilenet = NeuralNetClassifier(\n",
        "    # pretrained ResNet50 + custom classifier \n",
        "    module=MobileNet,          \n",
        "    # fine tuning model's inner parameters\n",
        "    module__output_features=13,\n",
        "    module__num_units=512,\n",
        "    module__drop=0.5,\n",
        "    module__num_units1=512,\n",
        "    module__drop1=0.5,\n",
        "    # criterion\n",
        "    criterion=nn.CrossEntropyLoss,\n",
        "    # batch_size = 128\n",
        "    batch_size=20,\n",
        "    # number of epochs to train\n",
        "    max_epochs=100,\n",
        "    # optimizer Adam used\n",
        "    optimizer=torch.optim.Adam,\n",
        "    optimizer__lr = 0.0025,\n",
        "    optimizer__weight_decay=1e-6,\n",
        "    # shuffle dataset while loading\n",
        "    iterator_train__shuffle=True,\n",
        "    # load in parallel\n",
        "    iterator_train__num_workers=4,\n",
        "    # stratified kfold split of loaded dataset\n",
        "    train_split=CVSplit(cv=5, stratified=True, random_state=42),\n",
        "    # callbacks declared earlier\n",
        "    callbacks=[lr_scheduler_mobilenet, checkpoint_mobilenet, \n",
        "                early_stopping_mobilenet],\n",
        "    # use GPU or CPU\n",
        "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "mobilenet.initialize()\n",
        "\n",
        "mobilenet.load_params(f_params='/content/drive/MyDrive/chess_weights/best_model4_mobilenet.pkl')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skorch/dataset.py:271: FutureWarning: Setting a random_state has no effect since cv is not a float. This will raise an error in a future. You should leave random_state to its default (None), or set cv to a float value.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Xnuo_EZfTP"
      },
      "source": [
        "def test_transform():\n",
        "    return A.Compose([A.Resize(96, 96), A.Normalize(),\n",
        "    AT.ToTensor()])\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_list, transforms=None):\n",
        "        super().__init__()\n",
        "        self.image_list =image_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image = self.image_list[index]\n",
        "        if self.transforms:\n",
        "            sample = {\n",
        "                'image': image,\n",
        "            }\n",
        "            sample = self.transforms(**sample)\n",
        "            image = sample['image']\n",
        "\n",
        "        return image\n",
        "\n",
        "def createDataset(path,batch_size):\n",
        "    test_dataset = TestDataset(path, test_transform())\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "    return test_loader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhMgyqS_YMIs",
        "outputId": "6bf8c3c6-500a-47eb-e7df-c23cfe48e324"
      },
      "source": [
        "class Detector():\n",
        "    def __init__(self, device, model, testloader,classes):\n",
        "        self.model = model\n",
        "        self.loader = testloader\n",
        "        self.device = device\n",
        "        self.classes=classes\n",
        "        self.figures={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0}\n",
        "\n",
        "    def predict(self):\n",
        "        desc=[]\n",
        "        images = next(iter(self.loader))\n",
        "        preds = np.array([])\n",
        "        predmobile = np.append(preds, self.model.predict(images).tolist())\n",
        "        for el in predmobile.flatten():\n",
        "          self.figures[el]+=1\n",
        "        print('DenseNet169 prediction done!')\n",
        "        return self.figures,np.array(predmobile).reshape(8,8)\n",
        "\n",
        "from PIL import Image\n",
        "from chessboard_detection import inference, loadImage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os \n",
        "\n",
        "def cropChessboard(im, tiles, folder='resized', padding = 12, n = 50):\n",
        "    pictures = []\n",
        "    for tile in tiles:\n",
        "        xyxy = [min(tile[0:2]), min(tile[2:4]), max(tile[0:2]), max(tile[2:4])]\n",
        "        xyxy[0] -= padding\n",
        "        xyxy[1] -= padding\n",
        "        xyxy[2] += padding\n",
        "        xyxy[3] += padding\n",
        "        xyxy = [max(0, int(c)) for c in xyxy]    # preventing negative and float coordinates \n",
        "        cropped = im[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2]]\n",
        "        cropped = Image.fromarray(cropped)\n",
        "\n",
        "        cropped = cropped.resize((n, n), resample=Image.BILINEAR)\n",
        "        \n",
        "        #cropped.save(f'{folder}/{k}.jpg')\n",
        "        pictures.append(np.array(cropped))\n",
        "    return pictures # np.array\n",
        "img_path   = '/content/5.jpg'\n",
        "imgg = loadImage(img_path)\n",
        "img= cv2.imread(img_path)\n",
        "tiles = inference(imgg)\n",
        "res = cropChessboard(img, tiles)\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "classes={0:'Empty',1:'whitePawn',2:'whiteBishop',3:'whiteKnight',4:'whiteRook',5:'whiteQueen',6:'whiteKing',7:'blackPawn',8:'blackBishop',9:'blackKnight',10:'blackRook',11:'blackQueen',12:'blackKing'}\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "            \n",
        "\n",
        "\n",
        "test_loader = createDataset(res, 70)\n",
        "detector = Detector(device,mobilenet,test_loader,classes)\n",
        "figures,desc = detector.predict()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/chessboard_detection.py:218: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(contours), hierarchy[0]\n",
            "/content/chessboard_detection.py:200: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  new_contours = new_contours[mask]\n",
            "/content/chessboard_detection.py:201: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  new_hierarchy = new_hierarchy[mask]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet169 prediction done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CqxKKVLcg5t",
        "outputId": "79e81fa7-69a2-4b67-b0b4-4826a45da72a"
      },
      "source": [
        "figures"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0,\n",
              " 1: 0,\n",
              " 2: 57,\n",
              " 3: 0,\n",
              " 4: 0,\n",
              " 5: 0,\n",
              " 6: 0,\n",
              " 7: 5,\n",
              " 8: 0,\n",
              " 9: 1,\n",
              " 10: 0,\n",
              " 11: 0,\n",
              " 12: 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qUi9xUVYg10",
        "outputId": "b5524ed2-441e-4a4b-9e87-2f36458a52cd"
      },
      "source": [
        "fl=desc.flatten()\n",
        "\n",
        "value= np.bincount(fl.astype('int64')).argmax()\n",
        "figures.pop(value, None)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzSlBCH6asEm",
        "outputId": "a2afaa83-5232-4f19-ff2a-c13898b44046"
      },
      "source": [
        "#desc[desc == value] = "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
              "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
              "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
              "        2.,  2.,  9.,  7., 12.,  2.,  2.,  2.,  7.,  2.,  2.,  2.,  2.,\n",
              "        2.,  2.,  2.,  7.,  2.,  2.,  7.,  2.,  2.,  7.,  2.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0MYoDEWbX96",
        "outputId": "03d0de47-542f-4757-cf96-d3af9378c779"
      },
      "source": [
        "value"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxm8KVB6b30u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}